# Simpler is Better: Few-shot Semantic Segmentation with Classifier Weight Transformer. ICCV2021.

## Introduction

We proposed a novel model training paradigm for few-shot semantic segmentation. Instead of meta-learning the whole, complex segmentation model, we focus on the simplest
classifier part to make new-class adaptation more tractable. Also, a novel meta-learning algorithm that leverages a Classifier Weight Transformer (CWT) for adapting dynamically the classifier weights to every query sample is introduced to eliminate the impact of intra-class discripency. 

## Architecture
<a href="url"><img src="https://github.com/zhiheLu/STAR_Stochastic_Classifiers_for_UDA/blob/master/digit_signal_classification/doc/architecture.jpg" align="center" height="300" width="300" ></a>

Code will be released soon.
